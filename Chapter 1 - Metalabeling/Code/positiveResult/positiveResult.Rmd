---
title: "Proof of concept Meta-labeling"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Libraries
```{r echo=FALSE, results="hide"}
library(caret)  # Wrapper for Random Forest
library(rvest)  # Defines  %>%

set.seed(1998)
# _____ Neural Networks _____
library(keras)
library(tensorflow)
tensorflow::tf$random$set_seed(1998)
# _______________

library(ROCR)  # ROC plots
library(ggplot2)  # Plots
library(data.table)  # Melting df

setwd("~/Dropbox/HKUST/TFG/Chapter\ 1\ -\ Metalabeling/Code/positiveResult")

source("utils/utilities.R")
```

```{r}
# _____ Hyper-parameters _____

nObs <- 1000  # Std: 1000

nFeatures <- 5  # Std: 5
nFeaturesM1 <- 2  # Std: 2

sigma <- 0.5  # Std: 0.5
sigmaEps <- 2  # Std: 0.3
# _______________

allSigmaEps <- seq(from = 0, to = 3, length.out = 31)

naiveModel <- matrix(rep(NA, 3*length(allSigmaEps)), 
                     ncol = 3, nrow = length(allSigmaEps),
                     byrow = TRUE)
colnames(naiveModel) <- c("recall", "precision", "F1Score")

allF1Scores <- allRecall <- allPrecision <- matrix(rep(NA, 2*length(allSigmaEps)), 
                                                   ncol = 2, nrow = length(allSigmaEps),
                                                   byrow = TRUE)
colnames(allF1Scores) <- colnames(allRecall) <- colnames(allPrecision) <- c("M1", "MM")

sigmoid <- function(z) {
  return(1/(1 + exp(-z)))
}

set.seed(1998)
alpha <- rnorm(1, mean = 0.3, sd = sigma)
betas <- rnorm(nFeatures - 1, mean = 0, sd = sigma)
means <- rnorm(nFeatures, mean = 0, sd = sigma)
betas <- c(betas, 
           -(alpha + sum(betas*(means[1:(nFeatures - 1)])))/means[nFeatures])

# alpha + sum_k (beta_k * mean_k) = 0

for (k in 1:length(allSigmaEps)) {
  sigmaEps <- allSigmaEps[k]
  dd <- cbind(rnorm(nObs, mean = 0, sd = sigmaEps), 
              rep(1, nObs), 
              rnorm(nObs, mean = means[1], sd = sigma), 
              rnorm(nObs, mean = means[2], sd = sigma), 
              rnorm(nObs, mean = means[3], sd = sigma), 
              rnorm(nObs, mean = means[4], sd = sigma), 
              rnorm(nObs, mean = means[5], sd = sigma))
  colnames(dd) <- c("epsilon", "1", "X1", "X2", "X3", "X4", "X5")
  
  y <- sigmoid(dd %*% c(1, alpha, betas))
  y <- as.numeric(y > 0.5)
  # y[y == 0] <- -1
  # y <- factor(y)
  
  x <- dd[, (ncol(dd) - nFeatures + 1):(ncol(dd) - nFeatures + nFeaturesM1)]
  # x <- dd[, (ncol(dd) - nFeatures + 1):ncol(dd)]
  
  if (is.null(dim(x))) {
    inSampleInd <- sample(length(x), ceiling(0.8*nObs))
    trnInd <- sample(length(inSampleInd), ceiling(0.8*length(inSampleInd)))
    
    xinSample <- x[inSampleInd]
    yinSample <- y[inSampleInd]
    
    xTrn <- xinSample[trnInd]
    yTrn <- yinSample[trnInd]
    
    xVal <- xinSample[-trnInd]
    yVal <- yinSample[-trnInd]
    
    xTst <- x[-inSampleInd]
    yTst <- y[-inSampleInd]
    
  } else {
    inSampleInd <- sample(nrow(x), ceiling(0.8*nObs))
    trnInd <- sample(length(inSampleInd), ceiling(0.8*length(inSampleInd)))
    
    xinSample <- x[inSampleInd, ]
    yinSample <- y[inSampleInd]
    
    xTrn <- xinSample[trnInd, ]
    yTrn <- yinSample[trnInd]
    
    xVal <- xinSample[-trnInd, ]
    yVal <- yinSample[-trnInd]
    
    xTst <- x[-inSampleInd, ]
    yTst <- y[-inSampleInd]
  }
  
  primaryModel <- keras_model_sequential() %>%
    layer_flatten(input_shape = ncol(xTrn)) %>%
    layer_dense(units = 1, activation = "sigmoid",
                kernel_initializer = initializer_random_uniform(
                  minval = -0.05, maxval = 0.05, seed = 104))
  
  # Input format:
  # x <-> Matrix
  # y <-> vector
  
  primaryModel %>%
    compile(
      optimizer = "rmsprop",
      loss = "binary_crossentropy",
      metrics = c("Recall", "Precision")
    )
  
  history <- primaryModel %>% fit(
    x = xTrn, 
    y = yTrn,
    epochs = 100,
    batch_size = 256,
    validation_data = list(xVal, yVal),
    verbose = 1
    # validation_split = 0.2
  )
  
  yHatTrn <- primaryModel %>% predict(xTrn)
  yHatVal <- primaryModel %>% predict(xVal)
  yHatTst <- primaryModel %>% predict(xTst)
  
  # _____ Choosing a threshold _____
  {
    df <- data.frame("predictions" = yHatTst,
                     "labels" = yTst)
    pred <- prediction(df$predictions, df$labels)
    perf <- performance(pred, "tpr", "fpr")
    par(pty = "s")
    plot(
      perf,
      col = "grey40",
      lwd = 3,
      main = "ROC M1 (Test)"
    )
    # Line with a: intercept, b: slope, lty = line type
    
    abline(a = 0, b = 1, lty = "dotted")
  } 
  # _______________
  
  # _____ Secondary Model _____

  yHatTrn <- primaryModel %>% predict(xTrn)
  yHatVal <- primaryModel %>% predict(xVal)
  yHatTst <- primaryModel %>% predict(xTst)

  yinSample <- y[inSampleInd]
  yTrn <- yinSample[trnInd]
  yVal <- yinSample[-trnInd]
  yTst <- y[-inSampleInd]

  # M1: 2, M2: 3, n = 1000, sigmaEps = 0.3
  # xM2 <- dd[, (ncol(dd) - (nFeatures) + 1):ncol(dd)]
  xM2 <- dd[, (ncol(dd) - (nFeatures - nFeaturesM1) + 1):ncol(dd)]

  if (is.null(dim(xM2))) {
    xM2inSample <- xM2[inSampleInd]

    xM2Trn <- cbind(yHatTrn, xM2inSample[trnInd])
    yM2Trn <- (yHatTrn > 0.5) == (yTrn)

    xM2Val <- cbind(yHatVal, xM2inSample[-trnInd])
    yM2Val <- (yHatVal > 0.5) == (yVal)

    xM2Tst <- cbind(yHatTst, xM2[-inSampleInd])
    yM2Tst <- (yHatTst > 0.5) == (yTst)
  } else {
    xM2inSample <- xM2[inSampleInd, ]

    xM2Trn <- cbind(yHatTrn, xM2inSample[trnInd, ])
    yM2Trn <- (yHatTrn > 0.5) == (yTrn)

    xM2Val <- cbind(yHatVal, xM2inSample[-trnInd, ])
    yM2Val <- (yHatVal > 0.5) == (yVal)

    xM2Tst <- cbind(yHatTst, xM2[-inSampleInd, ])
    yM2Tst <- (yHatTst > 0.5) == (yTst)
  }

  set.seed(1998)
  secondaryModel <- keras_model_sequential() %>%
    layer_flatten(input_shape = ncol(xM2Trn)) %>%
    layer_dense(units = 25, kernel_initializer = initializer_random_uniform(
      minval = -0.05, maxval = 0.05, seed = 104)) %>%
    layer_activation_leaky_relu() %>%
    layer_dense(units = 1, activation = "sigmoid",
                kernel_initializer = initializer_random_uniform(minval = -0.05,
                                                                maxval = 0.05,
                                                                seed = 104))

  # Input format:
  # x <-> Matrix
  # y <-> vector

  secondaryModel %>% compile(
    optimizer = "rmsprop",
    loss = "binary_crossentropy",
    metrics = c("Recall", "Precision")
  )

  history <- secondaryModel %>% fit(
    x = xM2Trn,
    y = yM2Trn,
    epochs = 200,
    batch_size = 256,
    validation_data = list(xM2Val, yM2Val),
    verbose = 1
  )

  yHatM2Trn <- secondaryModel %>% predict_classes(xM2Trn)
  yHatM2Val <- secondaryModel %>% predict_classes(xM2Val)
  yHatM2Tst <- secondaryModel %>% predict_classes(xM2Tst)

  print(sum(yHatM2Trn))
  print(sum(yHatM2Val))
  print(sum(yHatM2Tst))

  yHatTrn <- 2*(yHatTrn > 0.5) - 1
  yHatVal <- 2*(yHatVal > 0.5) - 1
  yHatTst <- 2*(yHatTst > 0.5) - 1
  
  yinSample <- y[inSampleInd]
  yTrn <- 2*yinSample[trnInd] - 1
  yVal <- 2*yinSample[-trnInd] - 1
  yTst <- 2*y[-inSampleInd] - 1
  
  yHatMMTrn <- yHatTrn*yHatM2Trn
  yHatMMVal <- yHatVal*yHatM2Val
  yHatMMTst <- yHatTst*yHatM2Tst

  # _____ Meta Model _____
  TP <- sum((yHatMMTst == 1 & yTst == 1) | (yHatMMTst == -1 & yTst == -1))
  FP <- sum((yHatMMTst == 1 & yTst == -1) | (yHatMMTst == -1 & yTst == 1))
  TN <- sum((yHatMMTst == 0 & yHatTst == -1 & yTst == 1)
            | (yHatMMTst == 0 & yHatTst == 1 & yTst == -1))
  FN <- sum((yHatMMTst == 0 & yHatTst == -1 & yTst == -1)
            | (yHatMMTst == 0 & yHatTst == 1 & yTst == 1))

  confusionMatrixMMTst <- matrix(c(TP, FN,
                                   FP, TN), nrow = 2, ncol = 2, byrow = TRUE)
  colnames(confusionMatrixMMTst) <- c("1 Pred", "0 Pred")
  rownames(confusionMatrixMMTst) <- c("1 Actual", "0 Actual")

  recallMMTst <- TP/(TP + FN)
  precisionMMTst <- TP/(TP + FP)
  f1ScoreMMTst <- 2/(1/recallMMTst + 1/precisionMMTst)

  metricsMMTst <- c("recall" = recallMMTst, "precision" = precisionMMTst,
                    "f1Score" = f1ScoreMMTst)
  # _______________
  
  # _____ Primary Model _____
  
  TP <- sum((yHatTst == 1 & yTst == 1) | (yHatTst == -1 & yTst == -1))
  FP <- sum((yHatTst == 1 & yTst == -1) | (yHatTst == -1 & yTst == 1))
  TN <- 0
  FN <- 0
  
  confusionMatrixM1Tst <- matrix(c(TP, FN,
                                   FP, TN), 
                                 nrow = 2, ncol = 2, byrow = TRUE)
  colnames(confusionMatrixM1Tst) <- c("1 Pred", "0 Pred")
  rownames(confusionMatrixM1Tst) <- c("1 Actual", "0 Actual")
  
  recallM1Tst <- TP/(TP + FN)
  precisionM1Tst <- TP/(TP + FP)
  f1ScoreM1Tst <- 2/(1/recallM1Tst + 1/precisionM1Tst)
  
  metricsM1Tst <- c("recall" = recallM1Tst, "precision" = precisionM1Tst,
                    "f1Score" = f1ScoreM1Tst)
  
  # _______________
  
  print(confusionMatrixM1Tst)
  print(confusionMatrixMMTst)
  
  print(metricsM1Tst)
  print(metricsMMTst)

  metrics <- data.frame("Names" = names(metricsM1Tst),
                        "Primary.Model" = metricsM1Tst,
                        "Meta.Model" = metricsMMTst)
  rownames(metrics) <- 1:length(metricsM1Tst)
  dd.m <- melt(metrics, id.vars = "Names")
  colnames(dd.m)[2] <- "Model"

  allF1Scores[k, ] <- c(f1ScoreM1Tst, f1ScoreMMTst)
  allRecall[k, ] <- c(recallM1Tst, recallMMTst)
  allPrecision[k, ] <- c(precisionM1Tst, precisionMMTst)

  print(ggplot(dd.m, aes(x = Names, y = value)) +
          geom_bar(aes(fill = Model),
                   position = "dodge", stat = "identity", width = 0.6) +
          xlab(element_blank()) + ylab(element_blank()) +
          ggtitle("Metrics Toy Project - Meta-labeling") +
          scale_y_continuous(breaks = seq(from = 0, to = 1, length.out = 11)))

  # naiveModel[k, ] <- metricsM1Tst
  
  cat("\n")
  print(k)
}

# _____ Recall _____
dd <- data.frame(cbind(allSigmaEps, naiveModel[, 1]))
colnames(dd) <- c("Sigma", "Naive Model")
dd.m <- melt(dd, id.vars = "Sigma")
dd.m$value <- as.numeric(dd.m$value)
colnames(dd.m)[2] <- "Model"

ggplot(dd.m, aes(x = Sigma, y = value, col = Model)) +   
  geom_point(aes(col = Model), color = "springgreen3") +
  geom_line(aes(col = Model), color = "springgreen3") +
  labs(title = "Recall - Naive Model", 
       x = "Sigma", y = "Recall") +
  labs(col = "Model") 
# _______________
# _____ Precision _____
dd <- data.frame(cbind(allSigmaEps, naiveModel[, 2]))
colnames(dd) <- c("Sigma", "Naive Model")
dd.m <- melt(dd, id.vars = "Sigma")
dd.m$value <- as.numeric(dd.m$value)
colnames(dd.m)[2] <- "Model"

ggplot(dd.m, aes(x = Sigma, y = value, col = Model)) +   
  geom_point(aes(col = Model), color = "springgreen3") +
  geom_line(aes(col = Model), color = "springgreen3") +
  labs(title = "Precision - Naive Model", 
       x = "Sigma", y = "Precision") +
  labs(col = "Model") 
# _______________
# _____ F1-Score _____
dd <- data.frame(cbind(allSigmaEps, naiveModel[, 3]))
colnames(dd) <- c("Sigma", "Naive Model")
dd.m <- melt(dd, id.vars = "Sigma")
dd.m$value <- as.numeric(dd.m$value)
colnames(dd.m)[2] <- "Model"

ggplot(dd.m, aes(x = Sigma, y = value, col = Model)) +   
  geom_point(aes(col = Model), color = "springgreen3") +
  geom_line(aes(col = Model), color = "springgreen3") +
  labs(title = "F1-Score - Naive Model", 
       x = "Sigma", y = "F1-Score") +
  labs(col = "Model") 
# _______________

# allF1ScoresN4 <- allF1Scores
# allRecallN4 <- allRecall
# allPrecisionN4 <- allPrecision
# saveRDS(allF1ScoresN4, file = "F1ScoreN4.Rds")
# saveRDS(allRecallN4, file = "recallN4.Rds")
# saveRDS(allPrecisionN4, file = "precisionN4.Rds")
```